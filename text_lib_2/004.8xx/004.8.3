УДК 004.8
М.П. МОМЗИКОВА, О.И. ВЕЛИКОДНАЯ, М.Я. ПИНСКИЙ,
А.В. СИРОТКИН, А.Л. ТУЛУПЬЕВ, А.А. ФИЛЬЧЕНКОВ
ОЦЕНКА ВЕРОЯТНОСТИ
НАБЛЮДАЕМОЙ ПОСЛЕДОВАТЕЛЬНОСТИ
В БИНАРНЫХ ЛИНЕЙНЫХ ПО СТРУКТУРЕ
СКРЫТЫХ МАРКОВСКИХ МОДЕЛЯХ
С ПОМОЩЬЮ АПОСТЕРИОРНОГО ВЫВОДА
В АЛГЕБРАИЧЕСКИХ БАЙЕСОВСКИХ СЕТЯХ
Момзикова М.П., Великодная О.И., Пинский М.Я., Сироткин А.В., Тулупьев А.Л., Фильченков А.А. Оценка вероятности наблюдаемой последовательности в бинарных
линейных по структуре скрытых марковских моделях с помощью апостериорного
вывода в алгебраических байесовских сетях.
Аннотация. Скрытые марковские модели (СММ) и алгебраические байесовские сети
(АБС) представляют собой вероятностные графические модели, а потому во многом
похожи. СММ получила широкое применение, в то время как АБС пока не столь распространена, однако ее аппарат позволяет моделировать и решать задачи СММ. Цель
работы — решить первую задачу скрытых марковских моделей при помощи апостериорного вывода АБС. В статье предложен алгоритм для оценки вероятности наблюдаемой
последовательности в бинарных линейных по структуре СММ с помощью апостериорного вывода АБС.
Ключевые слова: скрытые марковские модели, алгебраические байесовские сети, бинарные линейные по структуре СММ, вероятностные графические модели.
Momzikova M.P., Velikodnaya O.I., Pinsky M.I., Sirotkin A.V., Tulupyev A.L., Filchenkov A.A.
An observed sequence probability estimate in binary linear hidden Markov models with
posterior inference in algebraic Bayesian networks.
Abstract. Hidden Markov models (HMM) and algebraic Bayesian networks (ABN) are probabilistic graphical models and because of that they are quit similar. HMM has wide application
while ABN are not so widespread, but its instruments allow to simulate and solve hidden Markov models problems. The goal of this work is to solve hidden Markov model first problem by
means of algebraic Bayesian network posterior inference. An algorithm of estimating probability of observed sequence in binary linear HMM by means of algebraic Bayesian network posterior inference.
Keywords: hidden Markov models, algebraic Bayesian networks, probabilistic graphical models.
1. Введение. Современное научное общество широко использует
вероятностные графические модели для моделирования различных
процессов в таких областях как распознавание речи, теория информации, машинный перевод, молекулярная биология[1, 4–7].
Скрытые марковские модели — инструмент для моделирования
информации временнóго ряда. СММ используются во многих совре122
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
менных системах распознавания речи [6], в большинстве приложений
вычислительной молекулярной биологии [11], в сжатии информации
[12], в системах статистического машинного перевода [7], приложениях компьютерного зрения [13].
Алгебраическая байесовская сеть (АБС) — это одна из математических моделей баз фрагментов знаний (ФЗ) с неопределенностью.
Она формализует знания (с неопределенностью) при помощи вероятностной логики. Развитие аппарата АБС осуществлялось с начала
1980-х годов, и на сегодняшний день в теории АБС существуют алгоритмы для решения различных задач, однако АБС все еще редко используются для практических целей [3].
Области применения АБС и СММ схожи. Поэтому возникает вопрос о том, можно ли их выражать друг через друга.
Это может быть полезно для использования научных разработок, полученных в одной из них, в более широком круге задач.
Цель работы — описание алгоритма решения первой задачи для
СММ, связь с апостериорным выводом АБС, а также решение первой
задачи СММ через АБС.
2. Теоретические основы. Теория скрытых марковских моделей
вводится по [4, 6, 8]; теория алгебраических байесовских сетей вводится по [2, 3].
Скрытая марковская модель (СММ) — модель, включающая в
себя набор наблюдений, набор скрытых состояний и удовлетворяющая следующим свойствам:
1. P  qt 1 qt , qt 1 , qt  2 , , q1   P  qt 1 qt  — марковское свойство;
2.
P  ot o1 ,
oT , q1 ,
наблюдения
, qT   P  ot qt  —
только
зависимость
текущего
от
текущего
состояния,
где
последовательность
наблюдений,
O  o1 , o2 , oT  —
Q  q1 , q2 , qT  — последовательность состояний.
Скрытая марковская модель состоит из следующих объектов:
1. Набор возможных значений скрытых состояний:
S  s1 , s2 , sN  ;
2.
Последовательность
Q  q1 , q2 , qT  ;
скрытых
состояний
во
времени:
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
123
3.
Матрица
переходных
вероятностей:
aij  P  qt 1  s j qt  si  , 1  i, j  N ;
4.
5.
A  aij  ,
Вектор начального распределения:    i  ,  i  P  q1  si  ,
1 i  N ;
Алфавит
возможных
значений
наблюдений:
V  v1 , v2 , vM  ;
6. Последовательность
                    O  o1 , o2 , oT  ;
7. Матрица
наблюдений
вероятностей


во
наблюдений:
времени:
B  b j  k  ,
b j (k )  P vk  ot s j  qt , 1  j  N , 1  k  M .
В расчетах, связанных со скрытыми марковскими моделями,
пользуются представлением СММ в виде набора матриц вероятностей:
   A, B,   .
В теории СММ сформулированы три основных задачи:
Задача 1. Правдоподобие наблюдений.
Дана СММ с известными матрицами вероятностей. Определить
вероятность поступающей последовательности наблюдений во времени относительно этой СММ.
Формальная постановка задачи: даны последовательность наблюдений O  o1 , o2 , oT  и модель    A, B,   . P  O    ?
Для данной задачи существуют различные решения, например,
алгоритм «вперед–назад» [10].
Задача 2. Декодирование скрытой последовательности.
Даны СММ с оценками вероятности и поступившая последовательность наблюдений. Требуется определить наиболее вероятную
последовательность скрытых состояний.
Формальная постановка задачи: даны последовательность наблюдений O  o1 , o2 , oT  и модель    A, B,   . Найти наиболее вероятную последовательность скрытых состояний Q  q1 , q2 , qT  , соответствующую данной последовательности наблюдений.
Данная задача решается с помощью алгоритма Витерби [14].
Задача 3. Обучение СММ.
Изменить (настроить) матрицы вероятностей СММ таким образом, чтобы максимизировать вероятности поступающего набора по124
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
следовательностей наблюдений. То есть требуется обучить СММ на
наборе тренировочных последовательностей наблюдений.
Формальная постановка задачи: настроить параметры модели
   A, B,   так, чтобы максимизировать P  O   .
Данную задачу можно решать с помощью алгоритма Баума–
Вэлха [15].
Для преобразования в АБС в данной работе будем использовать
бинарные линейные по структуре СММ. Это такие СММ, у которых
могут быть только два скрытых состояния  S  s1 , s2  и два вида
наблюдений
V  v , v  .
1
2
В
последнем
будет
иметь
место
S  V  0,1  {true, false} .
Алгебраическая байесовская сеть — математическая модель базы фрагментов знаний с неопределенностью [1]. Фрагмент знаний
представляется в виде идеала конъюнктов с оценками их истинности.
Пусть имеется следующее:
T — конечный набор элементарных пропозиций;
S  s1 , s2 , , sk  — непустое подмножество T ;
S   v1v2
vr : v1 , v2
vr  S , r  0
k — конъюнкты (множество
положительно означенных конъюнкций над S );
S   S  \ e — идеал конъюнкта (множество положительно
означенных конъюнктов без пустого конъюнкта). В идеале существует
один максимальный элемент (максимальная по длине конъюнкция) и
множество минимальных элементов (одноатомных конъюнкций).
Квант Q  x0 x1 xn 1 — конъюнкция, которая для любой атомарной переменной из алфавита содержит либо ее формулу, либо отрицание.
Нумерация конъюнктов и квантов. Каждому конъюнкту из
идеала xi xi
xi 0  i1   ik  n  1, k  n можно сопоставить номер
1
2
k
вида 2  2   2ik . Обозначим через ci конъюнкт с порядковым
номером i .
Выделим из кванта положительную часть. Номер получившегося
конъюнкта будет номером кванта. Обозначим через qi квант с порядковым номером i .
i1
i2
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
125
Вероятности конъюнктов и квантов. Вероятности, относящиеся
к ФЗ, удобно упорядочивать по номерам конъюнктов и квантов и
представлять в виде векторов:
1


 P(q0 ) 




P( c1 ) 
P(q1 ) 
Pc  
.
; Pq  






 P( c n ) 

 P(q n ) 


2 1 

2 1 
Выделяют две структуры алгебраических байесовских сетей: первичную и вторичную. Первичная структура АБС — это база фрагментов знаний. Вторичная структура АБС — это связи между ФЗ. Вторичная структура АБС определяется набором вершин и набором ребер
между ними. Вершины — это фрагменты знаний, они однозначно задаются глобальным индексом минимального конъюнкта. Ребра однозначно задаются двумя вершинами.
Виды свидетельств. Свидетельства делятся на детерминированные и недетерминированные.
Детерминированным называют свидетельство, сообщающее о
том, какой набор атомов означен положительно, а какой — отрицательно.
Стохастическое (как подмножество недетерминированных свидетельств) — свидетельство, представимое в виде фрагмента знаний с
точечными оценками.
АБС позволяют делать два вида выводов: априорный и апостериорный. Задача априорного вывода в ФЗ: по известным вероятностным
оценкам истинности заданных пропозициональных формул построить
вероятностную оценку формулы, не вошедшей в число заданных.
Для апостериорного вывода существуют две задачи:
1) оценить вероятности появления свидетельства при заданных
оценках.
2) оценить условные вероятности всех конъюнктов АБС относительно поступившего свидетельства.
3. Представление бинарных линейных по структуре СММ в
виде АБС. Начнем с примера. Рассмотрим простейшую линейную
бинарную СММ в четыре момента времени (рис. 1).
126
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
p  x 2 x1 
p  x1 x 0 
x0
p  o0 x0 
x1
p  o1 x 1 
x2
x3
p  o2 x2 
o1
o0
p  x3 x 2 
p  o3 x3 
o3
o2
Рис. 1. Линейная бинарная СММ в четыре момента времени.
Матрицы данной модели    A, B,   имеют следующий вид:
a
 00
A
a
 10
 b (v )
 0 0
B
 b (v )

 1 0
a   p( x x )
01  i i


a   p( x x )

11   i i

b (v )   p(oi x i )
0 1 


b (v )   p(o x )
1 1   i i
 
   p( x ) 
0 

      i .


    p( x ) 

 1 
i 

p( x x ) 
i i 

p( x
i

x )
i 

,
p(o x ) 
i i 


,
p(o x ) 
i i 

Теперь построим АБС, соответствующую рассмотренной СММ
(рис. 2).
Для нумерации вершин необходимо ввести алфавит. В алфавите
соответствующей АБС вершины будем чередовать oi и xi , начиная с
i  0 : o0 ,x0 ,o1 ,x1 , oN 1 ,xN 1 .
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
127
x 0 x1
p  x 0 x1 
x0
p  x0 
o0
o1
o0 x0
p  o0 x0 
o2
p  o2 
o1 x1
p  o1 x 1 
x 2 x3
p  x 2 x3 
x3
p  x3 
x2
p  x2 
x1
p  x1 
p  o1 
p  o0 
x1 x 2
p  x1 x 2 
o3
p  o3 
o2 x2
p  o2 x2 
o3 x3
p  o3 x3 
Рис. 2. АБС, соответствующая рассмотренной СММ.
Темно-серыми кружками отмечены узлы, соответствующие одноатомным конъюнктам, остальными — соответствующие двухатомным конъюнктам.
Проиндексируем алфавит следующим образом:
o0 : 20  1 ; x0 : 21  2 ; o1 : 22  4 ; x 1 : 23  8 ; o2 : 24  16 ; x2 :
25  32 ; o3 : 26  64 ; x3 : 27  128 .
Тогда глобальные индексы ФЗ будут следующими (в соответствии с правилами нумерации квантов и конъюнктов):
o0 x0 : 20  21  3
x0 x1 : 21  23  10
o1 x1 : 22  23  12
x1 x2 : 23  25  40
o2 x2 : 24  25  48
x2 x3 : 25  27  160
o3 x3 : 26  27  192
128
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
 p(e) 


 p x0 
 p x 
1


 p(x 0 x 1 ) 


 p(e) 


 p x2 
 p x 
3


 p(x 2 x 3 ) 


 p(e) 


 p x1 
 p x 
2


 p(x 1 x 2 ) 


 
 
 
 
 
 
x0x1
<x1>
x1x2
<x2>
x2x3
o3x3
 p(e) 


 p o3 
 p x 
3


 p(o 3 x 3 ) 


Рис. 3. Соответствующая АБС, изображенная как база ФЗ, изображены узлы и
векторы вероятностей, хранящиеся в них.
 p(e) 


 p o0 
 p x 
0


 p(o 0 x 0 ) 


o0x0
 p(e) 


 p o1 
 p x 
1 

 p(o 1 x 1 ) 


 
 
o1x1
<x
3>
 p(e) 


 p o2 
 p x 
2


 p(o 2 x 2 ) 


o2x2
 
 
 
 
 
 
Данная АБС содержит ФЗ вида (рис. 3)



 N 2
oi , xi  ,  xi , xi 1
i 0
, oN 1 , xN 1


и соответствующие вероятностные векторы
  p  e    p  e    N  2 
p e

 
 



  p  oi    p  xi   
 p  oN 1    .
,
,
 
 

 p  xN 1   
  p  xi    p  xi 1   


 p o x  

  p  oi xi    p  xi xi 1   
N 1 N 1 
 
 i  0 
 

Вершинами вторичной структуры будут ФЗ со своими глобальными индексами, ребра будут иметь вид
o x , x x
i i
i i 1
 ,  xi xi 1 , oi 1 xi 1 i 0  ,  oN 1 , xN 1  .
N 2
Для преобразования матриц вероятностей СММ в векторы вероятностей для ФЗ АБС, будем двигаться по набору ФЗ в АБС в следующем порядке: o0 x0 , x0 x1 , o1 x1 , x1 x2 , o2 x2 , x2 x3 , o3 x3 , и в порядке
продвижения заполнять соответствующие вероятностные вектора.
1) Рассмотрим ФЗ o0 x0 :
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
129
p  e   1;
p  o0   p  o0 x0   p  o0 x0  
 p  o0 x0   p  x0   p  o0 x0   p  x 0  
 bx0  o0     x0   bx 0  o0     x 0  ;
p  x0    0 ;
p  o0 x0   p  o0 x0   p  x0  .
Так как x0 — начальное состояние по времени, то p  x0     x0  ,
p  x0  — маргинальная вероятность.
2) Рассмотрим ФЗ x0 x1 :
p e  1 ;
p  x0     0  ;
p  x1   p  x1 x0   p  x 0   p  x1 x0   p  x 0  
 ax0 x1    x0   ax0 x1    x0  ;
p  x0 x1   p  x1 x0   p  x 0   ax0 x1    x0  .
3)
Рассмотрим o1 x1 . Вероятность p  x1  была вычислена на
предыдущем шаге:
p e  1 ;
p  o1   p  o1 x1   p  o1 x1  
 p  o1 x1   p  x1   p  o1 x1   p  x 1  
 bx1  o1   p  x1   bx1  o1   p  x1  ;
p  x1  ;
p  o1 x1   bx1  o1   p  x1  .
4) Рассмотрим x1 x2 :
p e  1 ;
p  x1  ;
130
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
p  x2   p  x2 x1   p  x 1   p  x2 x1   p  x 1  
 ax1 x2  p  x 1   ax1 x2  p  x 1  ;
p  x1 x2   p  x2 x1   p  x 1   ax1x2  p  x 1  .
Далее для всех временных шагов i для ФЗ вида oi xi вероятностные векторы будут иметь вид
1

 p e  

 b o  p x  b o  p x 
 p  oi     xi  i   i  x i  i   i   .

 p  xi   
p  xi 


 
 p o x   

bxi  oi   p  xi 
i i 



Для ФЗ вида xi xi 1 векторы будут иметь вид
1

 p e  


 
p  xi 

 p  xi    
.
 p  xi 1    axi xi1  p  x i   axi xi1  p  x i  



 p x x  


axi xi1  p  x i 
i i 1 



Замечание. Каждая p  xi  в этих векторах будет вычислена на ша p e 


p  xi 1  
ге i  1 в векторе 
.
 p  xi  

 px x 

i 1 i 

Будем рассматривать события:
элементарных событий:   o0 x0 o1 x1
можных означиваний),
o0 x0 o1 x1
on 1 xn 1 , пространство
on 1 xn 1 (множество всех воз

вероятностное пространство:  , 2 , p  ,


вероятностную семантику (распределение):  p  o0 x0 o1 x1
on 1 xn 1  .
4. Первая задача СММ и апостериорный вывод АБС. Пусть
дана СММ с оцененными матрицами вероятностей. Введем обозначения:
O  o1 , o2 , oT  — Последовательность наблюдений во времени,
   A, B,   — модель СММ,
А — матрица вероятностей переходов,
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
131
B — матрица вероятностных наблюдений,
 — вектор начального распределения,
S  {S1 , S2 , SN } — набор возможных значений скрытых состояний,
Q  {q1 , q2 , qT } — последовательность скрытых состояний.
Необходимо определить вероятность поступающей последовательности наблюдений во времени P(O | μ)  ? , относительно данной СММ.
Рассмотрим пример. Пусть S — множество слов русского языка.
Тогда составленные из этих слов предложения — последовательности
наблюдений. На большой учебной базе можно оценить вероятность
появления одного слова после другого (обучить СММ), тогда можно
будет оценивать вероятности разных предложений. Например вероятность сочетания слов «я был», «большой дом» велика, а «окно пряла»,
«проаиаи прпрп арвларл» мала или нулевая.
Данная задача решается алгоритмом «вперед–назад»[10].
Вариант 1 («вперед»). Используем «жадный» алгоритм. Нам не
нужно каждый раз заново составлять и просматривать новую временную последовательность состояний. Например, вместо того, чтобы
каждый раз оценивать вероятности всей последовательности наблюдений O  {o1 , o2 , oT } при скрытых состояниях Q  {q1 , q2 , qT } ,
можно рассматривать подпоследовательности O  {o1 , o2 , ot } при
Q  {q1 , q2 , qt } , запоминать их и использовать для вычисления вероятностей более длинных подпоследовательностей.
Рассмотрим вероятность наблюдения частичной последовательности O  {o1 , o2 , ot } и состояния si в момент времени t :
t  i   P  o1 , o2 , ot , qt  si | μ  .
Эти вероятности будут храниться в матрице {t (i)} размером
N  T . Каждый элемент данной матрицы  t (i) означает вероятность
оказаться в состоянии si , пройдя всевозможные состояния в моменты
времени [1 t  1] . Матрица строится следующим образом (рис. 4):
132
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
//инициализация
for i ← 1 to N
do α1(i) ← πi·bi(o1)
//индукция
for t ← 1 to T-1
do for j ← 1 to N
do for i ← 1 to N
do αt+1(j) ← αt+1(j) + αt(i)·aij
αt+1(j) ← αt+1(j)·bj(ot+1)
//вывод результата
for i ← 1 to N
do P(O|μ) ← P(O|μ) + αT(i)
Замечание. Время работы алгоритма составляет порядка O( N 2T )
вычислений (из-за тройного вложенного цикла).
Вариант 2 («назад»). Рассмотрим вместо  t (i) другие вероятности. Вместо подпоследовательностей вида O  {o1 , o2 , ot } будем
рассматривать подпоследовательности вида O  {ot 1 , ot 2 , oT } .
Вероятность наблюдения частичной последовательности наблюдений O  {ot 1 , ot 2 , oT } . При данной модели μ и состоянии si в момент времени t : t (i)  P(ot 1 , ot 2 , oT | qt  sn 1 , μ)
//инициализация
for i ← 1 to N
do βT (i) ← 1
//индукция
for t ← T-1 down to 1
do for i ← 1 to N
do for j ← 1 to N
do βt(i) ← βt(i) + aij·bj(ot+1)·βt+1(j)
//вывод результата
for i ← 1 to N
do P(O|μ) ← P(O|μ) + β1(i)
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
133
 t 1 (n) sn
anj
 t 1 (n  1) s
n 1
at ( j )
a( n 1) j
qj  sj
a1 j
 t 1 (1)
s1
ot 1
b j (ot 1 )
ot 1
Рис. 4. Пример вычисления  t ( j ) .
Матрица {t (i)} заполняется следующим образом:
Пояснение: Изначально t (i)  1 , т.к. считается, что если мы
находимся на шаге T в состоянии i , то мы в него наверняка уже попали (вероятность равна 1 ).
Замечание: Если решать данную задачу с вероятностями 1 (i) , то
время работы будет также порядка O( N 2T ) .
Одной из основных задач теории АБС является апостериорный вывод. Именно ради него замышлялись байесовские сети, и именно из-за
него они называются байесовскими (иногда апостериорный вывод –
это просто применен). Суть апостериорного вывода очень проста и
может быть проиллюстрирована на следующем примере.
134
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
a jn
sn
t ( j )
qt  si
a j ( n 1)
sn 1
t 1 (n)
bn (ot )
t 1 (n  1)
bn 1 (ot )
a j1
s1
 t 1 (1)
b1 (ot )
ot
ot 1
Рис. 5. Пример вычисления t ( j ) .
Предположим, что имеется байесовская сеть, хоть алгебраическая,
хоть доверия, в которой существует связь между переменными x и y
(в БСД это означает, что заданы условные вероятности P( y | x) ,
P( x | y) , в АБС — что заданы маргинальные вероятности P( x) , P( y) ,
P( xy) . При использовании данной системы оказывается, что высказывание y в рассматриваемой нами ситуации истинно. Очевидно, что эта
информация (в терминологии байесовских сетей эта информация
называется свидетельством) должна увеличить наши знания не только
об y , но и об x . Как отразится это на вероятности истинности x ?
В теории байесовских сетей для учета поступающих свидетельств
применяется аппарат условных вероятностей. В данном простейшем
случае можно просто записать по определению или по теореме Байеса:
P  x  P  y|x 
P ( xy )
P x | y =
=
P  x  P  y|x   (1  P( x)) P( y | x )
P  x
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
135
и получить требуемую вероятность как для АБС, так и для БСД.
Однако, обычно не все так просто.
Во-первых, структура байесовской сети может быть гораздо сложнее — нужно будет пересчитывать вероятность сразу нескольких узлов, связанных с тем узлом, о котором поступило свидетельство.
Во-вторых, оценки вероятностей этих узлов (в случае АБС) могут
быть не точечными, а интервальными.
В-третьих, само свидетельство вовсе не обязано иметь вид «высказывание y истинно» — оно может быть недетерминированным («вероятность истинности y равна 7 / 8 ») или даже содержать неопределенность недетерминированным («мы убедились, что y справедливо с вероятностью от 3 / 5 до 5 / 8 »).
5. Решение первой задачи для СММ через АБС. В ходе исследований удалось установить, что первая задача для СММ эквивалентна
первой задаче апостериорного вывода для АБС.
Первая задача СММ: Дана последовательность наблюдений
O  {o1 , o2 , oT } и модель μ  ( A, B,  ) . Какова вероятность наблюдаемой последовательности при условии данной модели P(O | μ)  ?
В терминах АБС данная задача будет формулироваться следующим
образом. Поступает детерминированное свидетельство, например
e  õ0 õ1õ2 õT каким-то образом означенное. Требуется оценить вероятность данного свидетельства P(e)  ?
Рассмотрим конкретно-означенное детерминированное свидетельство e  o0 ō1ō2 o3 . В теории АБС стандартный алгоритм первой задачи
апостериорного вывода может пропагировать только свидетельство,
полностью лежащее в ФЗ. Данное e  o0 ō1ō2 o3 принадлежит четырем
фрагментам знаний. Совершим преобразование, воспользовавшись
правилом Байеса:
P(o0 ō1ō2 o3 )  P(o0 ō1ō2 | o3 )·P(o3 ) 
P(o0 ō1 | ō2 o3 )·P(ō2 | o3 )·P(o3 )  P(o0 | ō1ō2o3 )·P(ō1 | ō2o3 )·P(ō2 | o3 )·P(o3 ) .
Теперь исходная вероятность состоит из произведения вероятностей свидетельств, полностью лежащих в соответствующих ФЗ. Будем
пропагировать, начиная с крайнего правого подсвидедетельства ( o3 ).
Оно будет поступать на вход к ФЗ o3 x3 . После его пропагации по всей
сети, каждый ФЗ будет иметь новые апостериорные оценки вероятностей P o3 (...). Для этих оценок вероятностей будем пропагировать ō2 ,
136
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
поступающее в ФЗ ō2 x2 , которое снова изменит оценки вероятностей
на апостериорные P o3ō2 (...), и т.д.
Каждый раз будем пропагировать в изменившуюся апостериорную
АБС единичные подсвидетельства, двигаясь справа налево.
В конце останется только перемножить вероятности единичных
подсвидетельств.
6. Заключение. Известно, что скрытые марковские модели (СММ)
могут быть представлены как частный случай динамических байесовских сетей доверия (БСД), которые, в свою очередь, могут быть преобразованы в алгебраические байесовские сети (АБС). Отсюда возник
естественный вопрос о связи СММ и АБС.
В данной работе приведены теория СММ, в том числе первая задача СММ, теория АБС, в частности апостериорный вывод АБС, а также
представление бинарной линейной по структуре СММ в виде АБС.
Доказана эквивалентность апостериорного вывода для АБС и первой
задачи СММ. Дан алгоритм решения первой задачи СММ, состоящей в
оценке вероятности последовательности наблюдений, в терминах апостериорного вывода АБС. Приведенный алгоритм решения работает за
полиномиальное от длины входа время.
Первая задача была решена через АБС, что является примером использования АБС в теории СММ и может упростить дальнейшее развитие теории АБС в применении к СММ. Однако для этого необходимо проведение исследований. За рамками статьи остаются открытыми
вопросы, связанные со второй и третьей задачами СММ, которые также разрешимы в теории АБС, однако еще не было создано конкретных
алгоритмов решения.
Литература
1.
2.
3.
4.
5.
6.
7.
Николенко С.И., Тулупьев А Л. Самообучающиеся системы. М.: МНЦМО, 2009.
288 с.
Тулупьев А.Л. Алгебраические байесовские сети. Логико-вероятностный подход к
моделированию баз знаний с неопределенностью. СПб.: СПИИРАН, 2000. 292 с.
Тулупьев А.В., Николенко С.И., Сироткин А.В. Байесовские сети: логиковероятностный подход. СПб.: Наука, 2006.
Cowell R. G., Dawid A. P., Lauritzen S. L., Spiegelhalter D. J. Probabilistic Networks
and Expert Systems. NY.: Springer-Verlag, 1999.
Huang X., Acero A., Hsiao-Wuen Hon Spoken Language Processing. Prentice Hall,
2001. ISBN 0-13-022616-5.
Huang X., Jack M., and Ariki Y. Hidden Markov Models for Speech Recognition. Edinburgh University Press, 1990. ISBN 0748601627
Jurafsky D., Martin J.H. Speech and Language Processing: An Introduction to Natural
Language Processing, Speech Recognition, and Computational Linguistics. 2nd edition.
Prentice-Hall, 2009.
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
137
8.
9.
10.
11.
12.
13.
14.
15.
Stengel M. Introduction to Graphical Models, Hidden Markov Models and Bayesian
Networks. Department of Information and Computer Sciences Toyohashi University of
Technology Toyohashi, 441-8580 Japan, 2003.
Момзикова М.П., Великодная О.И., Пинский М.Я., Сироткин А.В., Тулупьев А.Л.,
Фильченков А.А. Представление бинарных линейных по структуре скрытых марковских моделей в виде алгебраических байесовских сетей // Труды СПИИРАН.
2010. Вып. 1 (12). [в печати]
Yu S.-Z., Kobayashi H. An Efficient Forward–Backward Algorithm for an ExplicitDuration Hidden Markov Model. IEEE SIGNAL PROCESSING LETTERS, Vol. 10,
No. 1, JANUARY 2003
da-Silva C. Q. Hidden Markov models applied to a subsequence of the Xylella fastidiosa
genome. Genet. Mol. Biol. Vol.26 No.4 São Paulo Dec. 2003.
Li J., Gray R. M. Image Segmentation and Compression Using Hidden Markov Models.
1st edition. Springer, 2000. ISBN 0792378997.
Bunke H., Caelli T. Hidden Markov Models Applications in Computer Vision. Series in
Machine Perception and Artificial Intelligence, Vol. 45, 2001. ISBN: 978-981-024564-1.
Forney D. G. The Viterbi Algorithm. Proceedings of the IEEE, Vol. 61, No. 3, March
1973.
Welch L. R. Hidden Markov Models and the Baum-Welch Algorithm. IEEE Information
Theory Society Newsletter, Vol. 53, No.4, December 2003. ISSN 1059-2362
Момзикова Мария Петровна — студент философского факультета С.-Петербургского
государственного университета (СПбГУ). Область научных интересов: вероятностнографические модели в автоматизированных информационных системах. Число научных
публикаций — 1. masya.momz@gmail.com, СПИИРАН, 14-я линия В.О., д. 39, г. СанктПетербург, 199178, РФ; р.т. +7(812)328-3337, факс +7(812)328-4450. Научный руководитель — д-р физ.-мат. наук, доцент А.Л. Тулупьев.
Momzikova Maria Petrovna — student of Faculty of Philosophy , SPbSU. Research area:
probabilistic graphical models in automated informational systems. The number of publications — 1. masya.momz@gmail.com, SPIIRAS, 14-th line V.O., 39, St. Petersburg, 199178,
Russia; office phone +7(812)328-3337, fax +7(812)328-4450. Scientific advisor — PhD in
Computer Science, Dr. of Sc. Associate Professor A.L. Tulupyev.
Великодная Ольга Игоревна — студент кафедры компьютерных технологий факультета информационных технологий и программирования СПб ГУ ИТМО.
velikola@yandex.ru, СПИИРАН, 14-я линия В.О., д. 39, г. Санкт-Петербург, 199178, РФ;
р.т. +7(812)328-3337, факс +7(812)328-4450. Научный руководитель — д-р физ.-мат.
наук, доцент А.Л. Тулупьев.
Velikodnaya Olga Igorevna — student of Computer Technologies Department, SPbITMO.
velikola@yandex.ru, SPIIRAS, 14-th line V.O., 39, St. Petersburg, 199178, Russia; office
phone +7(812)328-3337, fax +7(812)328-4450. Scientific advisor — PhD in Computer Science, Dr. of Sc. Associate Professor A.L. Tulupyev.
Пинский Михаил Яковлевич — студент кафедры компьютерных технологий факультета информационных технологий и программирования СПб ГУ ИТМО.
138
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
mikhailpinsky@gmail.com, СПИИРАН, 14-я линия В.О., д. 39, г. Санкт-Петербург,
199178, РФ; р.т. +7(812)328-3337, факс +7(812)328-4450. Научный руководитель — д-р
физ.-мат. наук, доцент А.Л. Тулупьев.
Pinsky Mikhail Iakovlevich — student of Computer Technologies Department, SPbITMO.
mikhailpinsky@gmail.com, SPIIRAS, 14-th line V.O., 39, St. Petersburg, 199178, Russia;
office phone +7(812)328-3337, fax +7(812)328-4450. Scientific advisor — PhD in Computer
Science, Dr. of Sc. Associate Professor A.L. Tulupyev
Сироткин Александр Владимирович — младший научный сотрудник лаборатории
теоретических и междисциплинарных проблем информатики СПИИРАН. Область научных интересов: алгебраические байесовские сети: вычислительные аспекты логиковероятностного вывода в условиях неопределенности. Число научных публикаций — 40.
avs@iias,spb.su, www.tulupyev.spb.ru; СПИИРАН, 14-я линия В.О., д. 39, г. СанктПетербург, 199178, РФ; р.т. +7(812)328-3337, факс +7(812)328-4450.
Sirotkin Alexander Vladimirovich — junior researcher, Theoretical and Interdisciplinary
Computer Science Laboratory, SPIIRAS. Research interests: algebraic Bayesian networks,
algorithms of probabilistic-logic inference under uncertainty. The number of publications —
40. avs@iias,spb.su, www.tulupyev.spb.ru; SPIIRAS, 39, 14-th Line V.O., St. Petersburg,
199178, Russia; office phone +7(812)328-3337, fax +7(812)328-4450.
Тулупьев Александр Львович — д.ф.-м.н., доцент; заведующий лабораторией теоретических и междисциплинарных проблем информатики СПИИРАН, доцент кафедры
информатики математико-механического факультета С.-Петербургского государственного университета (СПбГУ). Область научных интересов: представление и обработка
данных и знаний с неопределенностью, применение методов математики и информатики
в социокультурных исследованиях, применение методов биостатистики и математического моделирования в эпидемиологии, технология разработки программных комплексов с СУБД. Число научных публикаций — 210. ALT@iias.spb.su, www.tulupyev.spb.ru;
СПИИРАН, 14-я линия В.О., д. 39, г. Санкт-Петербург, 199178, РФ; р.т. +7(812)328-3337,
факс +7(812)328-4450.
Tulupyev Alexander Lvovich — PhD in Computer Science, Dr. of Sc.. Associate Professor;
Head of Theoretical and Interdisciplinary Computer Science Laboratory, SPIIRAS, Associate
Professor of Computer Science Department, SPbSU. Research area: uncertain data and
knowledge representation and processing, mathematics and computer science applications in
socio-cultural studies, biostatistics, simulation, and mathematical modeling applications in
epidemiology, data intensive software systems development technology. Number of publications — 210. ALT@iias.spb.su, www.tulupyev.spb.ru; SPIIRAS, 14-th line V.O., 39, St. Petersburg, 199178, Russia; office phone +7(812)328-3337, fax +7(812)328-4450.
Фильченков Андрей Александрович — аспирант кафедры информатики математикомеханического факультета С.-Петербургского государственного университета (СПбГУ),
младший научный сотрудник лаборатории теоретических и междисциплинарных проблем информатики СПИИРАН. Область научных интересов: автоматическое обучение
вероятностных графических моделей. Число научных публикаций — 9. aaafil@mail.ru,
СПИИРАН, 14-я линия В.О., д. 39, г. Санкт-Петербург, 199178, РФ; р.т. +7(812)328-3337,
факс +7(812)328-4450. Научный руководитель — д-р физ.-мат. наук, доцент А.Л. Тулупьев.
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
139
Filchenkov Andrey Alexandrovich — PhD student of Computer Science Department,
SPbGU, junior researcher, Theoretical and Interdisciplinary Computer Science Laboratory,
SPIIRAS Research area: machine learning of probabilistic graphical models. The number of
publications — 9. aaafil@mail.ru, SPIIRAS, 14-th line V.O., 39, St. Petersburg, 199178, Russia; office phone +7(812)328-3337, fax +7(812)328-4450. Scientific advisor — PhD in Computer Science, Dr. of Sc. Associate Professor A.L. Tulupyev
Рекомендовано лабораторией ТиМПИ, заведующий лабораторией А.Л. Тулупьев, д-р
физ.-мат. наук, доцент.
Статья поступила в редакцию 10.12.2010.
Поддержка исследования. Работа выполнена при финансовой поддержке РФФИ, проект No 09-01-00861-а «Методология построения интеллектуальных систем поддержки
принятия решений на основе баз фрагментов знаний с вероятностной неопределенностью».
140
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
РЕФЕРАТ
Момзикова М.П., Великодная О.И., Пинский М.Я., Сироткин А.В., Тулупьев А.Л., Фильченков А.А. Оценка вероятности наблюдаемой последовательности в бинарных линейных по структуре скрытых
марковских моделях с помощью апостериорного вывода в алгебраических байесовских сетях.
Для моделирования различных процессов в таких областях, как распознавание речи, теория информации, машинный перевод, молекулярная биология,
широко используются вероятностные графические модели, в том числе скрытые марковские модели и байесовские сети. В работе рассматривается первая
задача для скрытых марковских моделей, а также ее связь с логиковероятностным апостериорным выводом в алгебраических байесовских сетях.
Необходимость проведения исследований в указанном направлении состоит в том, чтобы использовать методы одних моделей к решенным, и, что
важно, к нерешенным проблемам других моделей. В теоретическом введении
были изложены основы теории скрытых марковских моделей и алгебраических байесовских сетей, включая основные задачи, сформулированные для
этих разновидностей вероятностно-графических моделей, необходимые для
понимания основного содержания работы.
В данной статье был изложен способ представления одной из разновидностей скрытых марковских моделей в виде алгебраических байесовских сетей. Была сформулирована первая задача для скрытых марковских моделей, а
так же приведен алгоритм «вперед–назад» для ее решения, работающий за
полиномиальное времени от входа.
Специфицирован вывод в алгебраических байесовских сетей, его результат совпадает с решением первой задачи скрытых марковских моделей.
Таким образом, в статье решена одна из основных задач скрытых марковских моделей через применение алгоритмического аппарата алгебраические
байесовские сети, что является примером использования последних в теории
скрытых марковских моделей и может упростить дальнейшее развитие теории
алгебраических байесовских сетей в применении к подобным моделям.
Однако отметим, что для использования полученного теоретического результата в практических целях требуется проведение дальнейших исследований. Для того чтобы решать задачи, сформулированные для скрытых марковских моделей, с помощью алгебраических байесовских сетей, необходимо
представить другие классические задачи теории скрытых марковских моделей
в виде задач логико-вероятностного вывода в теории алгебраических байесовских сетей. Также необходимо отметить, что предложенный в данной работе
алгоритм носит частный характер, и одним из направлений дальнейших исследований может стать поэтапное обобщение алгоритма преобразования скрытой марковской модели в алгебраическую байесовскую сеть на все разновидности скрытых марковских моделей.
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru
141
SUMMARY
Momzikova M.P.,
Velikodnaya O.I.,
Pinsky M.I.,
Sirotkin A.V.,
Tulupyev A.L., Filchenkov A.A. An observed sequence probability estimate in binary linear hidden Markov models with posterior inference
in algebraic Bayesian networks.
Probabilistic graphical models including hidden Markov models and Bayesian
networks are widespread in process of modeling in such fields as speech recognition, information theory, machine translation and molecular biology. The first problem of hidden Markov models and algebraic Bayesian network posterior inference
are overviewed and interconnection between them.
A necessity of researches for the specified direction is caused by ability to apply methods of first model in solved and, that is essential, unsolved problems of
another model. Also there are observed areas of practical use of hidden Markov
models. In theoretical introduction bases of theories of algebraic Bayesian networks
and hidden Markov models were given. The main objects of hidden Markov model
theory and algebraic Bayesian network theory were formulated. It is useful to mention that the only necessary minimum of the theories was given.
In this article the way of representation of one of hidden Markov models varieties in the form of algebraic Bayesian networks was stated.
The first problem of hidden Markov models is formulated and the forward–
backward algorithm for its solution is suggested. Its complexity is shown to be polynomial. Posterior inference of algebraic Bayesian networks is introduced and its
equivalence with the first problem of hidden networks is shown.
Thereby one of the fundamental problems of hidden Markov models problems
is solved by means of algebraic Bayesian networks instrumentality. This is an example of using algebraic Bayesian networks in theory of hidden Markov models and
it might simplify further researches in using algebraic Bayesian networks as hidden
Markov models.
However it is necessary to notice that for use of the obtained theoretical result
in the practical purposes carrying out of the further researches is required. To solve
the problems formulated for hidden Markov models by means of algebraic Bayesian
network theory it is necessary to present other classical problems of hidden Markov
model theory in the form of a logical probabilistic conclusion problems in algebraic
Bayesian network theory. Also it is necessary to notice that the algorithm offered in
this work has particular character, and one of directions of the further researches the
generalization of algorithm of transformation hidden Markov model into algebraic
Bayesian network for all the hidden Markov models varieties can be.
142
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru

k for all the hidden Markov models varieties can be.
142
Труды СПИИРАН. 2010. Вып. 2(13). ISSN 2078-9181 (печ.), ISSN 2078-9599 (онлайн)
SPIIRAS Proceedings. 2010. Issue 2(13). ISSN 2078-9181 (print), ISSN 2078-9599 (online)
www.proceedings.spiiras.nw.ru

