1Н
Б
УДК 004.8
Н.А. Новоселова, И.Э. Том, О.В. Красько
Объединенный институт проблем информатики,
г. Минск, Беларусь
novosel@newman.bas-net.by
Нечеткое нейросетевое моделирование
для получения интерпретируемого набора
классифицирующих правил
В статье рассматривается процесс построения нечеткой нейросетевой классифицирующей модели
(ННМ) на основе имеющихся числовых значений признаков. В связи с необходимостью построения
ННМ, обладающей достаточной степенью интерпретируемости при сохранении точности
классификации, предлагается использовать трехэтапный подход к генерированию набора нечетких
классифицирующих правил.
Введение
Задача классификации является одной из наиболее важных задач анализа
данных и состоит в отнесении некоторого объекта, характеризующегося набором
признаков, к одному из нескольких предопределенных классов. Использование
нечеткого моделирования для решения задач классификации обусловлено возможностью
получения компактных интерпретируемых наборов правил, достаточно точно
классифицирующих данные. В статье представлен процесс построения нечеткой
нейросетевой модели, состоящий из трех этапов [1]: инициализации начальной
структуры ННМ, обучения параметров ННМ и оптимизации структуры ННМ.
1. Определение нечеткого классификатора
и архитектура нечеткой нейросетевой модели
Нечеткий классификатор представляет собой систему нечетких правил,
которые описывают m классов в имеющемся наборе исходных данных. Предпосылки
правил задают область действия правил в n-мерном признаковом пространстве, а
следствиями правил являются метки классов из множества t i{C1,...,Cш}:
если p1  1 и ... pn   n , то tj, j = 1,..., M.
j
j
Правило Rj:
(1)
где M – количество правил, n – количество признаков, p = [p1,p2,...,pn]T – входной
вектор признаков, ti – следствие i-го правила,  1 ,...,  n – функции принадлежности
j
j
нечетких множеств. Степень активации j-го правила рассчитывается как:
n


 j ( x )    ij ( xi ) или  j ( x )  min (  ij ( xi )),
i 1
«Штучний інтелект» 2’2006
1 i  n
j  1,2,..., M .
211
Новоселова Н.А., Том И.Э., Красько О.В.
1Н
Выход классификатора определяется согласно стратегии «победитель забирает
все», т.е. выходом является класс, соответствующий следствию правила с
наибольшей степенью активации:
y  t* ,
j
j*  arg max (  j ) .
1 j  M
Нечеткая нейросетевая модель представляет собой сочетание нейронной сети и
нечеткого классификатора в единой однородной архитектуре (рис. 1), где:
– первый слой представляет входные признаки;
– скрытый слой представляет нечеткие правила;
– третий слой представляет выходные признаки;
– в качестве функций активации используются t-нормы и t-конормы (минимум и
максимум), нечеткие множества представляют собой веса соединений.
1
R
1
1
R
1(1)
x1
Выходной слой
С
С
1
R
2(1)
)
3(1
R
2(2)
1(2
)
x2
1
Веса – следствия
R
Слой правил
3(2)
Входной слой
Рисунок 1 – Нейросетевое представление нечеткого классификатора с пятью
правилами и двумя классами
2. Структурно-ориентированный метод инициализации
нечеткой нейросетевой модели
Предлагаемый в статье структурно-ориентированный метод инициализации
(ННМ) базируется на методе, описанном в работе Ванга и Менделя [2], и предполагает
начальное нечеткое разбиение области значений всех входных признаков для
дальнейшего создания набора нечетких правил вывода. Для описания алгоритма
обучения, реализующего предложенный метод, введем следующие обозначения:
L – обучающее множество размерности s, где ( p, t )  L является элементом
множества и состоит из входного вектора числовых значений признаков p  R n и
метки t принадлежности к одному из классов C1,...,Cm.
Rj = (A,C)  нечеткое правило классификации с предпосылкой A  ( 1 ,...,  n ) и
j
j
следствием C. Степень активации правила Rj рассчитывается R j ( p)  min (  ij ( pi )) ,
1i  n
 ij
212
– j-е нечеткое множество входного признака xi, j = 1,..., qi.
«Искусственный интеллект» 2’2006
Нечеткое нейросетевое моделирование...
1Н
cA – вектор из m компонент, представляющий собой степень принадлежности
предпосылки А к каждому классу для всех элементов обучающего множества.
PR  [1,1] – значение коэффициента эффективности правила R:
 0, если класс ( p )  следствие( R),
1
(2)
 L (1) k R( p), k   1
s ( p ,t )
в других случаях.

Далее опишем алгоритм создания некоторого заданного количества k max
нечетких правил вывода на основе обучающих данных:
1) выбрать элемент обучающего множества (p,t) из L;
2) для каждого входного признака найти функцию принадлежности  (i ) такую, что
j
PR 
i
 ij ( pi ) 
i
max { ij ( pi )} ;
(3)
j{1,...,qi }
3) если количество уже созданных правил меньше kmax и не существует правила
с предпосылкой вида
A  (  (j1) ,...,  (jn) ) ,
1
n
(4)
то создать нейрон ННМ для нового правила и соединить его с выходным узлом
соответствующего класса, определяемого меткой t;
4) если имеются нерассмотренные элементы обучающего множества и
количество правил k<kmax. то перейти к 1);
5) для каждого созданного правила с предпосылкой A рассчитать значения
вектора cA и определить класс с меткой tj в качестве следствия:
j  arg max {c i } ;
A
i{1,...,m}
6) для каждого правила рассчитать значения коэффициента эффективности PR.
3. Обучение параметров нечеткой нейросетевой модели
Для обучения параметров ННМ разработан эвристический алгоритм, который
основан на обратном распространении ошибки классификации каждого элемента
обучающего множества. Общая ошибка ННМ задается формулой:
1 n
1 n m
Ei    (tij  yij )2 ,

(5)
2 i 1
2 i 1 j 1
где m – количество классов или нейронов последнего слоя ННМ, tij и yij – желаемый
и действительный выход ННМ для входного вектора числовых признаков pi.
Величина ошибки правила Rj зависит как от ошибки выходного нейрона
соответствующего следствию правила, так и от текущей степени активации правила
Rj(p) и определяется как:
ER j  ( R j ( p ) * (1  R j ( p ))   ) * Eследствие( R j ) ,
(6)
e
где  – малое положительное число, например  = 0,01, Eследствие( R j ) – ошибка
выходного нейрона класса, соответствующего следствию правила Rj.
Алгоритм для настройки функций принадлежности состоит в следующем: если
степень активации правила должна быть увеличена, носитель нечеткого множества
«Штучний інтелект» 2’2006
213
1Н
Новоселова Н.А., Том И.Э., Красько О.В.
расширяется и смещается по направлению к текущему входному значению обучающего
элемента. Если же степень принадлежности должна быть уменьшена, осуществляется
обратное преобразование: носитель сжимается и смещается в направлении, обратном
текущему значению обучающего элемента.
4. Оптимизация структуры
нечеткой нейросетевой модели
Для оптимизации структуры используются четыре эвристических подхода:
– удаление избыточных признаков: входной признак, который имеет наименьшее
влияние на выходной признак, удаляется. Для определения этого признака используется
статистическая мера корреляции или хи-квадрат тест;
– удаление избыточных правил: правило, которое дает наименьшую суммарную
степень активации, удаляется;
– удаление элементов предпосылки правила: нечеткое множество, дающее
минимальную степень принадлежности в активном правиле для наименьшего числа
обучающих данных, удаляется;
– удаление нечетких множеств: определяется нечеткое множество с наибольшим
носителем и все элементы предпосылок правил, которые используют это нечеткое
множество, удаляются.
Описанные подходы реализованы в виде алгоритмов, которые применяются
итерационно.
Заключение
В статье описывается процесс построения разработанной авторами нечеткой
нейросетевой классифицирующей модели, которая позволяет находить решения задач
классификации в виде набора компактных и хорошо интерпретируемых нечетких
правил вывода. Предложенная ННМ может применяться для решения задач
классификации и прогнозирования в тех областях, где важным является не только
получение эффективного решения, но и понимание процесса его получения, как,
например, медицинская диагностика, принятие решений в бизнесе, военном деле и т.д.
Литература
1. Nauck D.D. Fuzzy data analysis with NEFCLASS // Journal of Approx. Reasoning. – 2003. – Vol. 32. –
P. 103-130.
2. L.X.Wang, J.M. Mendel Generating Fuzzy Rules by Learning from Examples // IEEE Trans. on Systems,
Man, and Cybernetics. – 1992. – Vol. 22. – P. 1414-1427.
Н.А. Новоселова, І.Е. Том, О.В. Красько
Нечітке нейромережне моделювання для отримання інтерпретованого набору класифікуючих правил
У статті розглядається процес побудови нечіткої нейромережної класифікуючої моделі (ННМ) на
основі наявних числових значень ознак. У зв’язку з необхідністю побудови ННМ, що володіє достатнім
ступенем інтерпретації при збереженні точності класифікації, пропонується використовувати трьохетапний
підхід до генерування набору нечітких класифікуючих правил.
N.A. Novoselova, I.E. Tom, O.V. Krasko
Neuro-Fuzzy Modeling for the Generation of Classification Rule Set
The current paper presents the development of the neuro-fuzzy classification model (NFM) on the basis of
the numerical feature values. In order to develop the NFC with high interpretability properties along with
sufficient classification accuracy the author proposes the three-stage approach to the generation of the fuzzy
classification rule set.
Статья поступила в редакцию 26.04.2006.
214
«Искусственный интеллект» 2’2006

